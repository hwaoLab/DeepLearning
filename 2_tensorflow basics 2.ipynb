{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tensorflow2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qV40U7mLZkN4","colab_type":"text"},"source":["# Tensorflow 실습 2"]},{"cell_type":"markdown","metadata":{"id":"AqnaCOhoZsTc","colab_type":"text"},"source":["python의 딥러닝 라이브러리인 Tensorflow에 대해 알아보자."]},{"cell_type":"markdown","metadata":{"id":"h5X9HqjFaFVK","colab_type":"text"},"source":["## 간단한 방식의 딥러닝 구현 "]},{"cell_type":"markdown","metadata":{"id":"Jx6UkuneSmBU","colab_type":"text"},"source":["### MNIST 데이터셋"]},{"cell_type":"markdown","metadata":{"id":"an123w8zaJKA","colab_type":"text"},"source":["<table>\n","  <tr><td>\n","    <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"600\">\n","  </td></tr>\n","  <tr><td align=\"center\">\n","    <b>그림 1.</b> MNIST 샘플 이미지 <br/>&nbsp;\n","  </td></tr>\n","</table>\n","\n","- 머신 러닝에서 사용되는 가장 기본적인 데이터 셋\n","- 손글씨로 쓰여진 0~9의 숫자들이 28*28 pixel 크기의 흑백 이미지 데이터로 저장되어 있음\n","- 주어진 이미지가 0~9 중 어떤 숫자인지 분류하는 model 을 만드는 것이 목표"]},{"cell_type":"code","metadata":{"id":"yS5f1KZnSqOJ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","# mnist dataset의 tf.keras.datasets.mnist로 쉽게 불러올 수 있음\n","mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# x는 이미지, y는 0부터 9까지 각 이미지에 맞는 label\n","print(x_train[0].shape)\n","print(x_train[0].dtype)\n","print(y_train[:5])\n","print(y_train[0])\n","plt.imshow(x_train[0], cmap='Greys')\n","plt.show()\n","\n","# training data로 60000개의 image, test data로 10000개의 image 사용\n","print(len(x_train))\n","print(len(x_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OoFTq8bWTVna","colab_type":"text"},"source":["### 모델 선언 및 학습, 평가"]},{"cell_type":"markdown","metadata":{"id":"K3lBBFyMTblr","colab_type":"text"},"source":["- tf.keras.models.Sequential 안에 tf.keras.layers의 layer들로 모델을 구성\n","작성한 순서대로 input에 각 layer가 적용됨\n","- Flatten : 28 * 28의 tensor를 784 size의 tensor로 펴주는 역할\n","- Dense : 임의의 size의 input을 특정한 size로 mapping 시켜주는 fully connected layer\n","- activation function으로 relu, softmax 등을 사용할 수 있음\n","- Dropout : dropout layer의 input에서 각각의 값에 대해, 일정 확률로 0값을 배정함\n","  - 학습 시에만 적용되며, test 할때는 적용되지 않음\n","  - overfitting을 막아주는 regularizer 역할\n","\n"]},{"cell_type":"code","metadata":{"id":"DtBVc8MzTayj","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dropout(0.2),\n","  tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","# model.complile에서는 optimizer, loss, metric을 지정\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sUirbA-fT2Mi","colab_type":"text"},"source":["- model.fit을 통해, 학습 데이터를 이용하여 학습함\n","  - validation_split=0.2 : 학습 데이터 중 80%는 학습에 이용하고, 20%는 매 epoch 마지막에 validation에 이용함\n","  - epoch=5 : 학습 데이터를 총 5번 활용하여 학습함\n","  - verbose=2 : 학습 log의 verbosity를 정하는 값\n","    - verbose = 1 > progress bar and one line per epoch\n","    - verbose = 0 > silent\n","    - verbose = 2 > one line per epoch\n","\n","- model.evaluate에서 학습된 모델을 이용하여, test 데이터에 대한 성능을 확인"]},{"cell_type":"code","metadata":{"id":"QOB_5E7vUChh","colab_type":"code","colab":{}},"source":["model.fit(x_train, y_train, validation_split=0.2, epochs=5, verbose=1)\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(\"test loss : %.3f, test accuracy : %.3f\" % (loss, accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DY38VG8OeSYt","colab_type":"text"},"source":["- 학습된 모델을 이용해서, 이미지에 대한 분류 결과를 출력하는 방법"]},{"cell_type":"code","metadata":{"id":"X4HfzRHoUi_N","colab_type":"code","colab":{}},"source":["y_pred = model.predict(x_test)\n","print(y_pred[:4])\n","print(tf.argmax(y_pred[:4], axis=-1))\n","\n","plt.imshow(x_test[0], cmap='Greys')\n","plt.show()\n","plt.imshow(x_test[1], cmap='Greys')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZVOIj2jKy77Y","colab_type":"text"},"source":["## tf.data.Dataset\n","- 일반적으로 데이터를 input으로 사용하기 위해 필요한 절차 (Extract, Transform, Load)\n","  - Extract: 파일로 저장된 데이터를 불러옴 (csv file, numpy file, tfrecord file 등)\n","  - Transform: 원하는 방식으로 전처리하거나, augmentation을 적용해야 하고(이미지 데이터 rotation, 텍스트 데이터 벡터화, 오디오 데이터의 signal process 등), random하게 batch를 구성\n","  - Load: transformed data를 GPU/TPU (accelerator devices)에 올려서 연산\n","\n","- 위와 같이 복잡한 input pipeline을 간단하게 처리할 수 있도록 지원하는 API\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C6Xsi5v_XR3e","colab_type":"text"},"source":["- 가상의 데이터인 x, y 생성\n","  - x는 총 10개의 2 x 3 data\n","  - y는 0부터 9까지 총 10개의 integer\n","  - 총 10개의 x, y가 짝을 이루는 dataset\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"0KlWlN1wZTfo","colab_type":"code","colab":{}},"source":["x = tf.random.normal([10, 2, 3])\n","y = [i for i in range(10)]\n","\n","dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","\n","batch_size = 4\n","\n","print(\"-----------batched dataset----------- \\n\")\n","# dataset.batch() function을 이용하여 dataset을 batch 단위로 나눌 수 있음\n","# batch size 4의 의미 : 전체 data를 4개씩 묶어서 불러옴\n","# tensorflow의 dataset은 for문을 통해 data를 불러올 수 있음\n","batched_dataset = dataset.batch(batch_size)\n","for batch in batched_dataset:\n","    print(\"start of batch\")\n","    x, y = batch\n","    print(\"x : \", x)\n","    print(\"y : \", y, \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FRIrP7nNXuRo","colab_type":"text"},"source":["- 위 출력 결과의 문제점\n","  - 전체 data가 순차적으로 구성\n","  - 학습 데이터는 random하게 batch를 구성하는 것이 필요\n"]},{"cell_type":"markdown","metadata":{"id":"-vBzJ0ynYLJR","colab_type":"text"},"source":["- 1 epoch : 전체 데이터를 한번 이용하는 것\n","\n","- dataset을 shuffle한 후, batch를 나누는 방법: 자동으로 epoch 마다 shuffle\n","  - buffer_size 만큼 순서대로 가져온 후, 그 안에서 shuffle 후 batch 구성\n","  - shuffle과 batch의 순서도 중요함\n","  - 20000장의 이미지가 있는데, 1번에서 10000번 까지는 고양이 이미지, 10001번부터 20000번 까지는 고양이가 아닌 이미지라고 하자.\n","    - 이 때 buffer_size=1000 이면 일단 1000개의 고양이 이미지를 가져온 후 shuffle, 즉 고양이로만 구성된 batch들을 구성하게 됨\n","    - 학습이 제대로 이루어지지 않음\n","  - buffer_size가 1이라면 섞이지 않음\n","  - 전체 data를 완전히 random하게 만들기 위해서는 buffer_size가 전체 data 개수와 같거나 크게 설정\n","\n","- 아래 실행 결과를 확인하면, 각 batch의 구성과 data의 순서가 random하게 바뀐 것을 확인할 수 있음 "]},{"cell_type":"code","metadata":{"id":"MVHBvIgZ30EF","colab_type":"code","colab":{}},"source":["epochs = 2\n","buffer_size = 10\n","\n","print(\"-----------shuffled dataset----------- \\n\")\n","shuffled_datatset = dataset.shuffle(buffer_size).batch(batch_size)\n","for epoch in range(epochs):\n","    print(\"start of epoch: \", epoch, \"\\n\")\n","    for batch in shuffled_datatset:\n","        print(\"start of batch\")\n","        x, y = batch\n","        print(\"x : \", x)\n","        print(\"y : \", y, \"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ocHbSGB6Y3ME","colab_type":"text"},"source":["### Transform을 위해, map 함수 활용 \n","- tf.data.Dataset에서 각각의 데이터에 대해 함수를 일관되게 적용하고 싶은 경우, dataset.map 함수를 이용함\n","- 결과를 보면, 기존 음수였던 값이 절대값 처리되어 양수로 변환된 것을 확인\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"zUcKpvkdZZkX","colab_type":"code","colab":{}},"source":["# tf.abs()를 input에 적용하는 함수\n","def abs_function(x):\n","    x = tf.abs(x)\n","    return x\n","\n","print(\"-----------dataset applied absolute function----------- \\n\")\n","\n","# lambda x, y의 의미: 모든 x, y에 대해 오른쪽과 같은 함수를 적용하라는 의미\n","abs_dataset = dataset.map(lambda x, y: (abs_function(x), y))\n","\n","# take()는 정해진 개수의 데이터를 가져오도록 하는 함수\n","for x, y in abs_dataset.batch(4).take(1):\n","    print(\"x : \", x)\n","    print(\"y : \", y, \"\\n\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qlc4wn-jZfOD","colab_type":"text"},"source":["(참고) tensorflow의 함수를 활용하지 않으면서, map 함수를 활용하는 방법\n","- 이전 예시에서는 tf function을 이용하였으므로, dataset map 함수가 정상적으로 작동\n","- 그러나 data에 전처리 또는 augmentation 할 때, tensorflow 함수가 아닌 별도의 패키지를 필요로하는 경우가 많음\n","- 앞에서와 동일한 구조로, np.abs를 활용하는 함수를 적용하면 아래와 같은 오류가 발생함\n","- Tensor를 numpy array로 변환할수 없다는 의미\n","\n"]},{"cell_type":"code","metadata":{"id":"3LiKKKibZyM3","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def numpy_abs_function(x):\n","    x = np.abs(x)\n","    return x\n","\n","try:\n","    print(\"-----------dataset applied numpy absolute function----------- \\n\")\n","    abs_dataset = dataset.map(lambda x, y: (numpy_abs_function(x), y))\n","    for x, y in abs_dataset.batch(4).take(1):\n","        print(\"x : \", x)\n","        print(\"y : \", y, \"\\n\")\n","except:\n","    print(\"=====Failure to use numpy function for dataset map function\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zM5xx-ZeZ6TG","colab_type":"text"},"source":["- tf.py_function : 일반적인 python function을 tensorflow에 알맞은 function으로 변환\n","  - input으로 함수, input list, output type을 넣어줌\n","- 위 함수를 이용하여 변환된 함수를 dataset map에 적용\n","- 오류 없이 작동하는 것을 확인\n"]},{"cell_type":"code","metadata":{"id":"uzv1HUd1Z4SL","colab_type":"code","colab":{}},"source":["# tf.py_function으로 tensorflow 외부 함수를 사용할 수 있게 변환\n","def tf_numpy_abs_function(x):\n","    tf_float = tf.py_function(\n","        numpy_abs_function,\n","        [x],\n","        tf.float32\n","    )\n","    return tf_float\n","\n","print(\"-----------dataset applied numpy absolute function----------- \\n\")\n","abs_dataset = dataset.map(lambda x, y: (tf_numpy_abs_function(x), y))\n","for x, y in abs_dataset.batch(4).take(1):\n","    print(\"x : \", x)\n","    print(\"y : \", y, \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uY39EjnUbbHD","colab_type":"text"},"source":["##Tensorboard"]},{"cell_type":"markdown","metadata":{"id":"KbRmvl_4cCw2","colab_type":"text"},"source":["- Tensorboard는 Tensorflow의 시각화 도구\n","- 측정값을 시각화 하거나 모델의 연산 Graph를 시각화 하는 도구를 제공함  \n","- 여기서는 uniform 분포를 따르는 값을 sampling하여, 1000step 동안 값을 저장함\n","\n"]},{"cell_type":"code","metadata":{"id":"gySKzRVwcPMs","colab_type":"code","colab":{}},"source":["# Log file을 저장할 path를 설정\n","tb_path = 'tensorboard'\n","# summary_writer를 만들고, log 값을 저장하고 싶은 경우에 활용함\n","summary_writer = tf.summary.create_file_writer(tb_path)\n","with summary_writer.as_default():\n","    for step in range(1000):\n","        # tf.summary.scalar는 tag, 값, step을 인자로 받음\n","        tf.summary.scalar('random uniform [0,1]', tf.random.uniform([1])[0], step=step)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WnlssfOLdOhz","colab_type":"text"},"source":["- 연산 그래프를 시각화 하는 방법\n","- 복잡한 딥러닝 모델의 연산도 그래프로 시각화 가능"]},{"cell_type":"code","metadata":{"id":"jl8aUurKfryp","colab_type":"code","colab":{}},"source":["# 연산 추적하도록 설정\n","tf.summary.trace_on(graph=True, profiler=True)\n","\n","# 연산하는 함수를 graph mode로 설정 (Autograph)\n","# Autograph: 함수 위에 @tf.function 데코레이터를 사용해주면, 함수 안의 연산을 자동으로 그래프 모드로 수행함\n","@tf.function\n","def opertation(x, y):\n","    x = tf.tanh(x)\n","    z = x + y\n","    return z\n","\n","# 연산 실행\n","x = tf.random.normal([1])\n","y = tf.random.uniform([1])\n","z = opertation(x, y)\n","\n","# 연산을 추적한 결과를 log file로 저장\n","with summary_writer.as_default():\n","    tf.summary.trace_export(name=\"trace\", step=0, profiler_outdir=tb_path)\n","\n","# 연산 추적 off\n","tf.summary.trace_off()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"csdxoDOtc8GW","colab_type":"text"},"source":["- 저장한 값을 시각한 결과"]},{"cell_type":"code","metadata":{"id":"f0FklhfDcr24","colab_type":"code","colab":{}},"source":["# Colab 환경에서 tensorboard를 사용하는 방법\n","%load_ext tensorboard\n","%tensorboard --logdir tensorboard/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f70uNrn4gvWr","colab_type":"text"},"source":["- Colab이 아닌 일반 컴퓨터에서 tensorboard를 활용하는 방법\n","  - cmd 창을 실행\n","  - 명령어 입력: tensorboard –-logdir=(로그파일 저장 경로)\n","  - 이후 노출되는 링크를 웹브라우저에 붙여넣으면 tensorboard 확인 가능\n","  - 일반적인 local 환경에서는 다음 링크를 사용 : http://localhost:6006/"]}]}